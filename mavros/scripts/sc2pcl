#!/usr/bin/env python
# vim:set ts=4 sw=4 et:
#
# Copyright 2015 UAVenture AG.
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
# or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License
# for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
# Updated: Tarek Taha : tarek.taha@kustar.ac.ae, Vladimir Ermakov
#    - Changed topic names after re-factoring : https://github.com/mavlink/mavros/issues/233
#    - Use mavros.setpoint module for topics

from sensor_msgs.msg import PointCloud2, LaserScan, PointField
from std_msgs.msg import Float64, Float32, Int32, String
from laser_geometry import LaserProjection as lp
from geometry_msgs.msg import PoseStamped, Quaternion, TwistStamped, TransformStamped #geometry
#import laser_geometry.laser_geometry as lg
import math
import rospy
import thread
import threading
import time
import numpy as np
import mavros
import scipy.signal as signal
import sensor_msgs.point_cloud2 as pc2
import pcl
#import pcl.pcl_visualization

from std_msgs.msg import Header #type 
from math import *
from mavros.utils import *
from mavros import setpoint as SP
from tf2_msgs.msg import TFMessage
from nav_msgs.msg import Odometry
#from pcl_helper import *
#from tf.transformations import quaternion_from_euler

class sc2pcl:

    def __init__(self):
        self.rate = rospy.Rate(50) # 10hz is the original
        self.laserProj = lp()
        self.x_demo = Float64()
        self.filtered_x = 0.0
        self.filtered_y = 0.0
        self.filtered_z = 0.0
        self.local_position = PoseStamped()
        self.odom = Odometry()
        self.covariance = 0.0
        self.scan_data = LaserScan()
        self.y = 0.0
        self.x = 0.0
        self.z = 0.0
        self.rx = 0.0
        self.ry = 0.0
        self.rz = 0.0
        self.seq_2 = 0.0
        self.X = 1.5
        self.Y = 0.0
        self.waypoints = Odometry()
        self.init = 0.0
        self.difference = 0.0
        self.waypoint_position = Odometry()
        self.waypoint_counter = 0.0
        self.pcl_data = pcl.PointCloud_PointXYZRGB()
        self.camera_depth = PointCloud2()


        rospy.Subscriber('/tf', TFMessage, self.callback_tf)
        rospy.Subscriber('/imu_odometry', Odometry, self.odom_callback)
        rospy.Subscriber("mavros/local_position/pose", PoseStamped, self.position_callback)
        rospy.Subscriber("waypoints", Odometry, self.waypoints_callback)
        rospy.Subscriber("/scan",  LaserScan, self.scan_callback) # subscription to range values from rplidar
        rospy.Subscriber("/camera/depth/points",  PointCloud2, self.camera_depth_callback) # subscription to range values from rplidar
        self.pub_vis = rospy.Publisher('/filtered_vision', PoseStamped, queue_size=10)
        self.filtered_x_pos = rospy.Publisher('filtered_x', Float64, queue_size=10)
        # self.covariance_pub = rospy.Publisher('covariance_sum', Float64, queue_size=10)
        self.pc = rospy.Publisher("converted_pc", PointCloud2, queue_size=10)
        # self.pc_rgb = rospy.Publisher("converted_pc_rgb", pcl.PointCloud_PointXYZRGB(), queue_size=1)
        self.waypoints_pub = rospy.Publisher('waypoints', Odometry, queue_size=10)
        self.pub_spt = rospy.Publisher('drone_transform', TransformStamped, queue_size=10)
        self.x_list = []
        self.y_list = []
        self.z_list = []
        i = 0.0

        while not rospy.is_shutdown():
            self.waypoints_assign()
            self.pcl_pub()
            if i < 15:
                # self.x_list.append(self.local_position.pose.position.x) 
                self.y_list.append(self.y) 
                self.x_list.append(self.x) 
                self.z_list.append(self.z) 
                i += 1
            else:
                self.filtered_y = np.median(self.y_list)
                self.filtered_x = np.median(self.x_list)
                self.filtered_z = np.median(self.z_list)
                self.y_list.pop(0)
                self.x_list.pop(0)
                self.z_list.pop(0)
                self.y_list.append(self.y) 
                self.x_list.append(self.x) 
                self.z_list.append(self.z) 
                self.filtered_estimator()
                # print i, self.y, self.filtered_y
            # print type(self.odom.pose.covariance), self.covariance
            

            # lalala = 0.0
            # random_cov = np.random.uniform(0.00493, 0.02273)
            # distance_from_drone = np.sqrt(((self.odom.pose.pose.position.x - self.local_position.pose.position.x)**2) + 
            #     ((self.odom.pose.pose.position.y - self.local_position.pose.position.y)**2)) 
            # data_pts = round((1.0/random_cov) / distance_from_drone)
            # lalalal= data_pts
            # lalala = int(lalala)
            #print data_pts, random_cov, distance_from_drone, self.covariance
            #print 1.0/random_cov

            self.follow()
            #print self.pcl_data.to_list

            self.rate.sleep()


    def camera_depth_callback(self, data):
        self.camera_depth = data

    def scan_callback(self, data): # callback invoked with the message as the first arg
        self.scan_data =  data

    def position_callback(self, data): # callback invoked with the message as the first arg
        self.local_position = data 

    def waypoints_callback(self, data): # callback invoked with the message as the first arg
        self.waypoint_position = data 

    def odom_callback(self, data): # callback invoked with the message as the first arg
        self.odom = data
        # x = 0.0 
        # for i in self.odom.pose.covariance:
        #     x += i 
        # self.covariance = x     
        # self.covariance_pub.publish(x)

    def waypoints_assign(self):
        if (np.abs(self.X - self.local_position.pose.position.x) < 0.2) and (np.abs(self.Y - self.local_position.pose.position.y) < 0.2) and (self.seq_2 == 0.0):
            self.seq_2 = self.seq_2 + 1  
            self.X = 5.0
            self.Y = 0.0
            self.difference = self.waypoint_position.header.seq - self.init
            self.init = self.waypoint_position.header.seq
            self.waypoint_counter += 1
            

        if (np.abs(self.X - self.local_position.pose.position.x) < 0.2) and (np.abs(self.Y - self.local_position.pose.position.y) < 0.2) and (self.seq_2 == 1.0):
            self.seq_2 = self.seq_2 + 1
            self.X = 5.0
            self.Y = -6.0
            self.difference = self.waypoint_position.header.seq - self.init
            self.init = self.waypoint_position.header.seq
            self.waypoint_counter += 1

        if (np.abs(self.X - self.local_position.pose.position.x) < 0.2) and (np.abs(self.Y - self.local_position.pose.position.y) < 0.2) and (self.seq_2 == 2.0):
            self.seq_2 = self.seq_2 + 1  
            self.X = 0.0
            self.Y = -6.0
            self.difference = self.waypoint_position.header.seq - self.init
            self.init = self.waypoint_position.header.seq
            self.waypoint_counter += 1

        if (np.abs(self.X - self.local_position.pose.position.x) < 0.2) and (np.abs(self.Y - self.local_position.pose.position.y) < 0.2) and (self.seq_2 == 3.0):
            self.seq_2 = self.seq_2 + 1  
            self.X = 0.0
            self.Y = 0.0
            self.difference = self.waypoint_position.header.seq - self.init
            self.init = self.waypoint_position.header.seq
            self.waypoint_counter += 1

        if (np.abs(self.X - self.local_position.pose.position.x) < 0.2) and (np.abs(self.Y - self.local_position.pose.position.y) < 0.2) and (self.seq_2 == 4.0):
            self.seq_2 = self.seq_2 + 1  
            self.X = 1.5
            self.Y = 0.0
            self.difference = self.waypoint_position.header.seq - self.init
            self.init = self.waypoint_position.header.seq
            self.waypoint_counter += 1

        if (np.abs(self.X - self.local_position.pose.position.x) < 0.2) and (np.abs(self.Y - self.local_position.pose.position.y) < 0.2) and (self.seq_2 == 5.0):
            self.seq_2 = self.seq_2 + 1  
            self.X = 5.0
            self.Y = 0.0
            self.difference = self.waypoint_position.header.seq - self.init
            self.init = self.waypoint_position.header.seq
            self.waypoint_counter += 1

        if (np.abs(self.X - self.local_position.pose.position.x) < 0.2) and (np.abs(self.Y - self.local_position.pose.position.y) < 0.2) and (self.seq_2 == 6.0):
            self.seq_2 = self.seq_2 + 1
            self.X = 5.0
            self.Y = -6.0
            self.difference = self.waypoint_position.header.seq - self.init
            self.init = self.waypoint_position.header.seq
            self.waypoint_counter += 1

        if (np.abs(self.X - self.local_position.pose.position.x) < 0.2) and (np.abs(self.Y - self.local_position.pose.position.y) < 0.2) and (self.seq_2 == 7.0):
            self.seq_2 = self.seq_2 + 1  
            self.X = 0.0
            self.Y = -6.0
            self.difference = self.waypoint_position.header.seq - self.init
            self.init = self.waypoint_position.header.seq
            self.waypoint_counter += 1

        if (np.abs(self.X - self.local_position.pose.position.x) < 0.2) and (np.abs(self.Y - self.local_position.pose.position.y) < 0.2) and (self.seq_2 == 8.0):
            self.seq_2 = self.seq_2 + 1  
            self.X = 0.0
            self.Y = 0.0
            self.difference = self.waypoint_position.header.seq - self.init
            self.init = self.waypoint_position.header.seq
            self.waypoint_counter += 1


        # self.waypoints.header.seq = self.odom.header.seq
        self.waypoints.pose.pose.position.x = self.X
        self.waypoints.pose.pose.position.y = self.Y
        self.waypoints.pose.pose.position.z = self.waypoint_counter

        self.waypoints_pub.publish(self.waypoints)

    def callback_tf(self,data):
        if data.transforms[0].header.frame_id == "camera_odom_frame":
            self.y = data.transforms[0].transform.translation.y
            self.x = data.transforms[0].transform.translation.x
            self.z = data.transforms[0].transform.translation.z
            self.rx = data.transforms[0].transform.rotation.x
            self.ry = data.transforms[0].transform.rotation.y
            self.rz = data.transforms[0].transform.rotation.z
        else:
            self.y = self.y
            self.x = self.x
            self.z = self.z
            self.rx = self.rx
            self.ry = self.ry
            self.rz = self.rz
        
    def pcl_pub(self):
        self.pc.publish(self.laserProj.projectLaser(self.scan_data))
        points_list = []

        for data in pc2.read_points_list(self.laserProj.projectLaser(self.scan_data), skip_nans=True):
             points_list.append([data[0], data[1], data[2], data[3]])
             print data, data[0], type(data[0])

        #self.pcl_data.from_list(points_list)
       
    #    visual = pcl.pcl_visualization.CloudViewing()
    #    visual.ShowMonochromeCloud(self.pcl_data, b'cloud')


    # def ros_to_pcl(self):
    # """ Converts a ROS PointCloud2 message to a pcl PointXYZRGB
    #     Args:
    #         ros_cloud (PointCloud2): ROS PointCloud2 message
    #     Returns:
    #         pcl.PointCloud_PointXYZRGB: PCL XYZRGB point cloud
    # """
    #     points_list = []

    #     for data in pc2.read_points(ros_cloud, skip_nans=True):
    #         points_list.append([data[0], data[1], data[2], data[3]])

    #     pcl_data = pcl.PointCloud_PointXYZRGB()
    #     pcl_data.from_list(points_list)

    #     return pcl_data


    def apply_median_filter(self, window_size=3):
        self.filtered_x = signal.medfilt(self.x_list, window_size)
        self.filtered_y = signal.medfilt(self.y_list, window_size)
        self.filtered_z = signal.medfilt(self.z_list, window_size)

        # for i in range(len(self.filtered_x)):
        #     self.x_demo.data = self.filtered_x[i]
        #     self.filtered_x_pos.publish(self.x_demo)
        #     print self.filtered_x[i], self.filtered_y[i], self.filtered_z[i]

    def filtered_estimator(self):

        # Initialise necessary headers
        pos = PoseStamped()
        pos.header = Header()
        pos.header.frame_id = "filtered_vision"

        pos.pose.position.x = self.filtered_x
        pos.pose.position.y = self.filtered_y
        pos.pose.position.z = self.filtered_z

        roll = self.rx 
        pitch = self.ry
        yaw = self.rz

        qx = np.sin(roll/2) * np.cos(pitch/2) * np.cos(yaw/2) - np.cos(roll/2) * np.sin(pitch/2) * np.sin(yaw/2)
        qy = np.cos(roll/2) * np.sin(pitch/2) * np.cos(yaw/2) + np.sin(roll/2) * np.cos(pitch/2) * np.sin(yaw/2)
        qz = np.cos(roll/2) * np.cos(pitch/2) * np.sin(yaw/2) - np.sin(roll/2) * np.sin(pitch/2) * np.cos(yaw/2)
        qw = np.cos(roll/2) * np.cos(pitch/2) * np.cos(yaw/2) + np.sin(roll/2) * np.sin(pitch/2) * np.sin(yaw/2)

        quaternion = [qx,qy,qz,qw]
        pos.pose.orientation = Quaternion(*quaternion)
            
        pos.header.stamp = rospy.Time.now() # Update timestamp for each published SP
        self.pub_vis.publish(pos)


    def follow(self): 
        # Initialise necessary headers
        pos = TransformStamped()
        pos.header = Header() # initialising a new header for a new PoseStamped()
        pos.header.frame_id = "convert pose to transform stamp"

        # Establish desired setpoints
        pos.transform.translation.x = self.local_position.pose.position.x 
        pos.transform.translation.y = self.local_position.pose.position.y
        pos.transform.translation.z = self.local_position.pose.position.z 

        # Establish desired orientation at setpoint
        roll_degrees = 0.0 
        roll = radians(roll_degrees)
        pitch_degrees = 0.0 
        pitch = radians(pitch_degrees)
        yaw_degrees = 0.0  
        yaw = radians(yaw_degrees)

        # Execute desired orientation
        # quaternion = quaternion_from_euler(roll, pitch, yaw) #roll,pitch,yaw
        # pos.pose.orientation = Quaternion(*quaternion)

        qx = np.sin(roll/2) * np.cos(pitch/2) * np.cos(yaw/2) - np.cos(roll/2) * np.sin(pitch/2) * np.sin(yaw/2)
        qy = np.cos(roll/2) * np.sin(pitch/2) * np.cos(yaw/2) + np.sin(roll/2) * np.cos(pitch/2) * np.sin(yaw/2)
        qz = np.cos(roll/2) * np.cos(pitch/2) * np.sin(yaw/2) - np.sin(roll/2) * np.sin(pitch/2) * np.cos(yaw/2)
        qw = np.cos(roll/2) * np.cos(pitch/2) * np.cos(yaw/2) + np.sin(roll/2) * np.sin(pitch/2) * np.sin(yaw/2)

        quaternion = [qx,qy,qz,qw]  # drone only takes in quarternion values, therefore have to do euler to quarternion conversion
        pos.transform.rotation = Quaternion(*quaternion)
        
        pos.header.stamp = rospy.Time.now() # Update timestamp for each published SP

        # Publishing to rostopic   
        self.pub_spt.publish(pos) # updated pose from pos.pose.orientation


                
if __name__ == '__main__':
    rospy.init_node('sc2pcl', anonymous=True)
    node = sc2pcl()
    rospy.spin() # spin() simply keeps python from exiting until this node is stopped
